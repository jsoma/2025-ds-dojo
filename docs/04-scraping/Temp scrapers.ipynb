{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e51879",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright codegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58112dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Placeholder for all data\n",
    "all_data = []\n",
    "\n",
    "# Start Playwright and browser\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)\n",
    "context = await browser.new_context()\n",
    "page = await context.new_page()\n",
    "await page.goto(\"https://jp.mercari.com/search?category_id=79\")\n",
    "\n",
    "while True:\n",
    "    # Scrape the current page\n",
    "    html = await page.content()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Locate all item listings by the `data-testid` attribute\n",
    "    items = soup.find_all('li', {'data-testid': 'item-cell'})\n",
    "    \n",
    "    for item in items:\n",
    "        # Extract relevant data fields\n",
    "        url_tag = item.find('a', {'data-testid': 'thumbnail-link'})\n",
    "        price_tag = item.find('span', {'class': 'number__6b270ca7'})\n",
    "        img_tag = item.find('img')\n",
    "        name_tag = item.find('div', {'class': 'imageContainer__f8ddf3a2'})\n",
    "        \n",
    "        data = {\n",
    "            'url': url_tag['href'] if url_tag else None,\n",
    "            'price': price_tag.text if price_tag else None,\n",
    "            'thumbnail': img_tag['src'] if img_tag else None,\n",
    "            'name': name_tag['aria-label'] if name_tag else None\n",
    "        }\n",
    "        \n",
    "        # Add the extracted data to the list\n",
    "        all_data.append(data)\n",
    "    \n",
    "    # Try to click the \"Next\" button\n",
    "    try:\n",
    "        await page.locator(\"a:has-text('\u6b21\u3078')\").click(timeout=10000)\n",
    "    except:\n",
    "        # If the button is not found, end the loop\n",
    "        break\n",
    "\n",
    "# Close browser\n",
    "await context.close()\n",
    "await browser.close()\n",
    "\n",
    "# Convert collected data to a pandas DataFrame and display\n",
    "df = pd.DataFrame(all_data)\n",
    "print(df.head())  # This will display the first few rows of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d29fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# Initialize an empty list to store product data\n",
    "all_data = []\n",
    "\n",
    "async def scrape_page(page):\n",
    "    # Wait for the page content to load\n",
    "    await page.wait_for_selector(\"li[data-testid='item-cell']\", timeout=10000)\n",
    "\n",
    "    # Get the HTML content of the page\n",
    "    content = await page.content()\n",
    "\n",
    "    # Parse the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # Find all product listing elements\n",
    "    items = soup.find_all(\"li\", {\"data-testid\": \"item-cell\"})\n",
    "\n",
    "    for item in items:\n",
    "        try:\n",
    "            # Extract product details with proper checks for missing elements\n",
    "            product_url = item.find('a')['href'] if item.find('a') else None\n",
    "            if product_url:\n",
    "                product_url = \"https://jp.mercari.com\" + product_url\n",
    "            \n",
    "            product_name = item.find('div', {'role': 'img'})['aria-label'] if item.find('div', {'role': 'img'}) else None\n",
    "            price = item.find('span', {'class': 'number__6b270ca7'}).text if item.find('span', {'class': 'number__6b270ca7'}) else None\n",
    "            image_url = item.find('img')['src'] if item.find('img') else None\n",
    "\n",
    "        except AttributeError:\n",
    "            # Handle any unexpected attribute errors\n",
    "            product_url = product_name = price = image_url = None\n",
    "\n",
    "        # Add data to the list as a dictionary\n",
    "        all_data.append({\n",
    "            'Product URL': product_url,\n",
    "            'Product Name': product_name,\n",
    "            'Price': price,\n",
    "            'Image URL': image_url\n",
    "        })\n",
    "\n",
    "# Start Playwright and run the scraping process\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)\n",
    "context = await browser.new_context()\n",
    "page = await context.new_page()\n",
    "\n",
    "# Go to the initial page\n",
    "await page.goto(\"https://jp.mercari.com/search?category_id=79\", timeout=10000)\n",
    "\n",
    "# Scrape data from all pages\n",
    "while True:\n",
    "    await scrape_page(page)\n",
    "    \n",
    "    # Try clicking the \"Next Page\" button\n",
    "    try:\n",
    "        await page.get_by_role(\"link\", name=\"\u6b21\u3078\").click(timeout=10000)\n",
    "    except:\n",
    "        # If the button is not found or there's an error, break the loop\n",
    "        break\n",
    "\n",
    "await context.close()\n",
    "await browser.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a pandas DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Show the first few rows to confirm the result\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93446875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mercari.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3f87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright, expect\n",
    "\n",
    "async def run(playwright):\n",
    "    browser = await playwright.chromium.launch(headless=False)\n",
    "    context = await browser.new_context()\n",
    "    page = await context.new_page()\n",
    "    await page.goto(\"https://suumo.jp/jj/chintai/ichiran/FR301FC005/?sc=13101&ar=030&bs=040&sd=1&ta=13&ts=1\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    while True:\n",
    "        await page.wait_for_selector(\".property\")  # Wait for property elements to load\n",
    "        \n",
    "        # Get all property elements on the current page\n",
    "        properties = await page.query_selector_all(\".property\")\n",
    "        \n",
    "        for property in properties:\n",
    "            title = await property.query_selector(\"h2.property_inner-title a\")\n",
    "            title_text = await title.inner_text()\n",
    "            link = await title.get_attribute(\"href\")\n",
    "            price = await property.query_selector(\".detailbox-property-point\")\n",
    "            price_text = await price.inner_text() if price else \"N/A\"\n",
    "            \n",
    "            # Add more fields as needed\n",
    "            \n",
    "            # Append the data as a dictionary\n",
    "            all_data.append({\n",
    "                \"title\": title_text,\n",
    "                \"link\": link,\n",
    "                \"price\": price_text,\n",
    "                # Add more fields here\n",
    "            })\n",
    "        \n",
    "        # Try to click the \"Next\" button\n",
    "        try:\n",
    "            next_button = await page.query_selector(\"p.pagination-parts a:has-text('\u6b21\u3078')\")\n",
    "            if next_button:\n",
    "                await next_button.click()\n",
    "            else:\n",
    "                break  # Exit if no next button found\n",
    "        except:\n",
    "            break  # Exit on any error (like timeout)\n",
    "    \n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.head()  # Display the first few rows\n",
    "    \n",
    "    await context.close()\n",
    "    await browser.close()\n",
    "\n",
    "async def main():\n",
    "    async with async_playwright() as playwright:\n",
    "        await run(playwright)\n",
    "\n",
    "# Run the main function\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75362cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"cleaning-worksheets/suumo-properties.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b3964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e746c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "workshop": {
   "title": "Temperature Data Scraper",
   "description": "Scraping weather and temperature data",
   "order": 7
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}