{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db903641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR IS Timeout 10000ms exceeded.\n",
      "Call log:\n",
      "waiting for locator(\"a:has-text('Next')\").first\n",
      "\n",
      "No more pages to scrape.\n",
      "             name price          tax  \\\n",
      "0            CORN   298  \u00a5298\uff088%tax\uff09   \n",
      "1     YUZU CITRON   358  \u00a5358\uff088%tax\uff09   \n",
      "2        BROCCOLI   398  \u00a5398\uff088%tax\uff09   \n",
      "3    CUCUMBER 1PC   128  \u00a5128\uff088%tax\uff09   \n",
      "4  CUCUMBERS 4PCS   498  \u00a5498\uff088%tax\uff09   \n",
      "\n",
      "                                           image_url           tags  \n",
      "0  https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
      "1  https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
      "2  https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
      "3  https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
      "4  https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "from playwright.async_api import async_playwright\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize an empty list to store product data\n",
    "product_data = []\n",
    "\n",
    "# Define the function to scrape a single page\n",
    "async def scrape_page(page):\n",
    "    html = await page.content()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Find all product elements on the page\n",
    "    products = soup.find_all(\"div\", class_=\"product_item\")\n",
    "    \n",
    "    for product in products:\n",
    "        # Extract relevant product details\n",
    "        name = product.find(\"dt\", class_=\"item_name\").get_text(strip=True) if product.find(\"dt\", class_=\"item_name\") else None\n",
    "        price = product.find(\"span\", class_=\"price01_default\").get_text(strip=True) if product.find(\"span\", class_=\"price01_default\") else None\n",
    "        tax = product.find(\"p\", class_=\"normal_price\").get_text(strip=True) if product.find(\"p\", class_=\"normal_price\") else None\n",
    "        image = product.find(\"img\")[\"src\"] if product.find(\"img\") else None\n",
    "        tags = product.find(\"ul\", class_=\"item_icon\").get_text(strip=True) if product.find(\"ul\", class_=\"item_icon\") else None\n",
    "        \n",
    "        # Append data to our list as a dictionary\n",
    "        product_data.append({\n",
    "            \"name\": name,\n",
    "            \"price\": price,\n",
    "            \"tax\": tax,\n",
    "            \"image_url\": f\"https://www.national-azabu.net{image}\" if image else None,  # Assuming image URL is relative\n",
    "            \"tags\": tags\n",
    "        })\n",
    "\n",
    "# Define the function to handle pagination\n",
    "async def scrape_all_pages():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "        \n",
    "        # Visit the first page\n",
    "        await page.goto(\"https://www.national-azabu.net/products/list?category_id=52\")\n",
    "        \n",
    "        # Scrape the first page\n",
    "        await scrape_page(page)\n",
    "        \n",
    "        # Handle pagination\n",
    "        while True:\n",
    "            try:\n",
    "                # Try clicking the \"Next\" button\n",
    "                await page.locator(\"a:has-text('Next')\").first.click(timeout=10000)\n",
    "                time.sleep(3)  # Wait for the next page to load\n",
    "                await scrape_page(page)\n",
    "            except:\n",
    "                print(\"No more pages to scrape.\")\n",
    "                break\n",
    "\n",
    "        # Convert the product data into a DataFrame\n",
    "        df = pd.DataFrame(product_data)\n",
    "        print(df.head())  # Display the first few rows of data\n",
    "        # Optionally save to CSV\n",
    "        df.to_csv(\"products_output.csv\", index=False)\n",
    "\n",
    "# Run the scraper\n",
    "await scrape_all_pages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b64fdbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>tax</th>\n",
       "      <th>image_url</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CORN</td>\n",
       "      <td>298</td>\n",
       "      <td>\u00a5298\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>PERISHABLE \u51b7\u8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YUZU CITRON</td>\n",
       "      <td>358</td>\n",
       "      <td>\u00a5358\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>PERISHABLE \u51b7\u8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BROCCOLI</td>\n",
       "      <td>398</td>\n",
       "      <td>\u00a5398\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>PERISHABLE \u51b7\u8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUCUMBER 1PC</td>\n",
       "      <td>128</td>\n",
       "      <td>\u00a5128\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>PERISHABLE \u51b7\u8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUCUMBERS 4PCS</td>\n",
       "      <td>498</td>\n",
       "      <td>\u00a5498\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>PERISHABLE \u51b7\u8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NAGAIMO</td>\n",
       "      <td>324</td>\n",
       "      <td>\u00a5324\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>PERISHABLE \u51b7\u8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>YAMATOIMO</td>\n",
       "      <td>632</td>\n",
       "      <td>\u00a5632\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>PERISHABLE \u51b7\u8535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>SATOIMO</td>\n",
       "      <td>590</td>\n",
       "      <td>\u00a5590\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>BABY POTATOES</td>\n",
       "      <td>298</td>\n",
       "      <td>\u00a5298\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>POTATOES BIG PACK</td>\n",
       "      <td>698</td>\n",
       "      <td>\u00a5698\uff088%tax\uff09</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows \u00d7 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name price          tax  \\\n",
       "0                 CORN   298  \u00a5298\uff088%tax\uff09   \n",
       "1          YUZU CITRON   358  \u00a5358\uff088%tax\uff09   \n",
       "2             BROCCOLI   398  \u00a5398\uff088%tax\uff09   \n",
       "3         CUCUMBER 1PC   128  \u00a5128\uff088%tax\uff09   \n",
       "4       CUCUMBERS 4PCS   498  \u00a5498\uff088%tax\uff09   \n",
       "..                 ...   ...          ...   \n",
       "110            NAGAIMO   324  \u00a5324\uff088%tax\uff09   \n",
       "111          YAMATOIMO   632  \u00a5632\uff088%tax\uff09   \n",
       "112            SATOIMO   590  \u00a5590\uff088%tax\uff09   \n",
       "113      BABY POTATOES   298  \u00a5298\uff088%tax\uff09   \n",
       "114  POTATOES BIG PACK   698  \u00a5698\uff088%tax\uff09   \n",
       "\n",
       "                                             image_url           tags  \n",
       "0    https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
       "1    https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
       "2    https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
       "3    https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
       "4    https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
       "..                                                 ...            ...  \n",
       "110  https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
       "111  https://www.national-azabu.net/upload/save_ima...  PERISHABLE \u51b7\u8535  \n",
       "112  https://www.national-azabu.net/upload/save_ima...            NaN  \n",
       "113  https://www.national-azabu.net/upload/save_ima...            NaN  \n",
       "114  https://www.national-azabu.net/upload/save_ima...            NaN  \n",
       "\n",
       "[115 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"products_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a5cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "async with async_playwright() as playwright:\n",
    "    browser = await playwright.chromium.launch(headless=False)\n",
    "    context = await browser.new_context()\n",
    "    page = await context.new_page()\n",
    "\n",
    "    base_url = \"https://www.national-azabu.net\"\n",
    "    category_url = f\"{base_url}/products/list?category_id=52\"\n",
    "    current_page = 1\n",
    "    all_products = []\n",
    "\n",
    "    while True:\n",
    "        # Visit the current page\n",
    "        await page.goto(f\"{category_url}&pageno={current_page}\")\n",
    "        await page.wait_for_selector(\"div.product_item\")  # Wait until product items are loaded\n",
    "        content = await page.content()  # Get the page content\n",
    "        soup = BeautifulSoup(content, \"html.parser\")  # Parse the content with BeautifulSoup\n",
    "\n",
    "        # Extracting product details\n",
    "        product_items = soup.select(\"div.product_item\")\n",
    "        \n",
    "        for product in product_items:\n",
    "            name = product.select_one(\"dt.item_name\").get_text(strip=True)\n",
    "\n",
    "            # Check if the price exists to avoid 'NoneType' errors\n",
    "            price_element = product.select_one(\"p.price01_default\")\n",
    "            price = price_element.get_text(strip=True) if price_element else \"N/A\"\n",
    "\n",
    "            img_element = product.select_one(\"div.item_photo img\")\n",
    "            img_url = img_element[\"src\"] if img_element else \"N/A\"\n",
    "            img_url = \"https://www.national-azabu.net\" + img_url if img_url != \"N/A\" else \"N/A\"\n",
    "\n",
    "            # Add product details to list\n",
    "            all_products.append({\n",
    "                \"name\": name,\n",
    "                \"price\": price,\n",
    "                \"img_url\": img_url\n",
    "            })\n",
    "\n",
    "        # Check if there's a \"Next\" button for pagination\n",
    "        next_button = await page.query_selector('li.pagenation__item-next a')\n",
    "        if not next_button:\n",
    "            break  # No more pages, exit the loop\n",
    "\n",
    "        current_page += 1  # Increment the page number\n",
    "\n",
    "    await context.close()\n",
    "    await browser.close()\n",
    "\n",
    "    # Create a pandas dataframe from the scraped data\n",
    "    df = pd.DataFrame(all_products)\n",
    "    df.head()  # Display the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a840c251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CORN</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YUZU CITRON</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BROCCOLI</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUCUMBER 1PC</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUCUMBERS 4PCS</td>\n",
       "      <td>N/A</td>\n",
       "      <td>https://www.national-azabu.net/upload/save_ima...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name price                                            img_url\n",
       "0            CORN   N/A  https://www.national-azabu.net/upload/save_ima...\n",
       "1     YUZU CITRON   N/A  https://www.national-azabu.net/upload/save_ima...\n",
       "2        BROCCOLI   N/A  https://www.national-azabu.net/upload/save_ima...\n",
       "3    CUCUMBER 1PC   N/A  https://www.national-azabu.net/upload/save_ima...\n",
       "4  CUCUMBERS 4PCS   N/A  https://www.national-azabu.net/upload/save_ima..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf6137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "workshop": {
   "title": "National Azabu Supermarket Scraper",
   "description": "Scraping product data from National Azabu",
   "order": 4
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}