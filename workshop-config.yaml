# Workshop configuration for データサイエンティストDOJO 2025
title: "データサイエンティストDOJO 2025"
description: "6-day intensive Python workshop for covering data analysis, APIs, web scraping, AI, and visualization"
github_repo: "jsoma/2025-ds-dojo"
github_branch: "main"
output_dir: "docs"
notebooks_branch: "codespaces"  # Branch with notebooks and data for Codespaces
site_url: "https://jsoma.github.io/2025-ds-dojo"
year: 2025

author: "Jonathan Soma"
organization: "Columbia Graduate School of Journalism"
author_title: "Knight Chair in Data Journalism"
email: "js4571@columbia.edu"
twitter: "@dangerscarf"
github: "https://github.com/jsoma"

platforms: [colab, codespaces]

codespaces:
  requirements:
    - pandas>=2.0.0
    - numpy>=1.24.0
    - matplotlib>=3.6.0
    - seaborn>=0.12.0
    - requests>=2.28.0
    - beautifulsoup4>=4.11.0
    - lxml>=4.9.0
    - playwright>=1.40.0
    - jupyter
    - ipywidgets>=8.0.0
    - tqdm>=4.65.0
    - openpyxl>=3.1.0

sections:
  # Day 1 - Monday
  - folder: 01-python-basics
    title: "Python Basics"
    description: "Introduction to Python programming, Jupyter notebooks, and basic data structures"
    slides: 01-python-basics/data-dojo-intro.pptx  # Will auto-convert to PDF
    links:
      - title: "Welcome Survey"
        url: "https://docs.google.com/forms/d/e/1FAIpQLSd6XdmBIu08J5iTvmZRDwmy9XCbTDLidQUeWW6lsXpW1m1EBA/viewform?usp=header"
      - title: "Python's Not (Just) For Unicorns"
        url: "https://littlecolumns.com/learn/python"
      - title: "Data Sources Survey"
        url: "https://docs.google.com/forms/d/e/1FAIpQLScMlXoLuRvLmTUASbEl2K_7Cr2ZBWEcH9rSO4V1x7zm_tklnQ/viewform?usp=header"
      - title: "A guide to Markdown"
        url: https://www.markdownguide.org/basic-syntax/
      - title: "Character encoding presentation"
        url: https://jonathansoma.com/projects/charsets/
    data_files:
      - 01-python-basics/学内違反データ.csv
      - 01-python-basics/学内違反データ.pdf
      - 01-python-basics/cheating.csv
      - 01-python-basics/cheating.pdf

  # Day 2 - Tuesday Morning
  - folder: 02-pandas
    title: "Data Analysis with Pandas"
    description: "Working with structured data using pandas: loading, cleaning, analyzing, and transforming datasets"
    slides: structured-data.pptx
    data_files:
      - "02-pandas/*.csv"
      - "02-pandas/*.xlsx"
    links:
      - title: Tokyo Open Data
        url: https://portal.data.metro.tokyo.lg.jp/
      - title: Gemini (Deep Research)
        url: "https://gemini.google/overview/deep-research/"
      - title: ChatGPT (turn on Deep Research)
        url: "https://chatgpt.com/"
      - title: Claude (turn on Research)
        url: "https://claude.ai/"
      - title: My restaurant data report (Google Gemini)
        url: https://g.co/gemini/share/cae3a2a8f5bd
      - title: My restaurant data report (Claude)
        url: https://claude.ai/public/artifacts/a76aabb6-6d06-47ed-9f21-6e0652f01d58
      - title: My restaurant data report (ChatGPT)
        url: https://chatgpt.com/s/dr_68eee03093c88191a2c0b21e5c0e50d7
  # Day 2 - Tuesday Afternoon
  - folder: 03-apis
    title: "Working with APIs"
    description: "Accessing data from web APIs programmatically, handling JSON responses, and paginated results"
    slides: structured-data.pptx
    api_keys_url: "https://bit.ly/nikkei-api-keys-2025"
    links:
      - title: "Inspect Element - Undocumented APIs"
        url: "https://inspectelement.org/"
      - title: "Using Paginated APIs (Video)"
        url: "https://www.youtube.com/watch?v=4Fdyft-ky0w"
    draft: false

  # Day 3 - Wednesday
  - folder: 04-scraping
    title: "Web Scraping"
    description: "Extracting data from websites using BeautifulSoup and Playwright, handling dynamic content"
    slides: 04-scraping/nikkei-scraping.pptx  # 106MB - will convert to PDF
    data_files:
      - "*.csv"
      - "*.xlsx"
    links:
      - title: "Automatic Scraper Tutorial"
        url: "https://www.youtube.com/watch?v=QNKxzkNpsko"
    draft: true

  # Day 4 - Thursday Part 1
  - folder: 05-ai
    title: "AI for Journalism"
    description: "Using AI tools for data extraction from PDFs, text analysis, and document processing"
    slides: 05-ai/03-dojo-practical-ai.pptx  # 141MB!
    data_files:
      - "pdfs/*.pdf"
      - "*.pdf"
      - "*.png"
    links:
      - title: "Claude for Sheets Example"
        url: "https://docs.google.com/spreadsheets/d/1vC7k7ft9TsPDud2rl3MOMqUZBxdJbC4jQ59QEMPP0nY/edit"
      - title: "Hugging Face"
        url: "https://huggingface.co/models"
      - title: "Anything LLM"
        url: "https://anythingllm.com/"
    draft: true

  # Day 4 - Thursday Part 2
  - folder: 06-visualization
    title: "Data Visualization"
    description: "Creating effective data visualizations with matplotlib, seaborn, and online tools like Datawrapper. Also covers PDF extraction techniques."
    slides: 06-visualization/Visualization.pptx  # 68MB
    data_files:
      - "*.csv"
      - "*.pdf"
      - "*.jpg"
      - "*.png"
    links:
      - title: "Feltron Report"
        url: "http://feltron.com/"
      - title: "Dear Data"
        url: "https://www.dear-data.com/theproject"
      - title: "Designing Viz"
        url: "https://designingviz.com/"
      - title: "Datawrapper"
        url: "https://www.datawrapper.de/"
      - title: "Datawrapper Academy"
        url: "https://academy.datawrapper.de/"
      - title: "Flourish"
        url: "https://flourish.studio/"
      - title: "Tabula - PDF Data Extraction"
        url: "https://tabula.technology/"
    draft: true

  # Day 5 - Friday / Day 6 - Monday
  - folder: 07-projects
    title: "Final Projects"
    description: "Project work time, troubleshooting, and presentations of data journalism projects"
    slides: 07-projects/nikkei-projects.pptx  # 4MB
    draft: true

git_lfs_threshold_mb: 50  # Will catch large PPTX files

# Footer and contact information
footer:
  copyright: "©2025, Jonathan Soma"
  contact:
    - "Email: [js4571@columbia.edu](mailto:js4571@columbia.edu)"
    - "Twitter: [@dangerscarf](https://twitter.com/dangerscarf)"
    - "GitHub: [jsoma](https://github.com/jsoma)"

# External links
external_links:
  workshop_signup: "https://www.nikkeibp.co.jp/seminar/nb/ddojo/"
  short_url: "https://bit.ly/ds-dojo-2025"

metadata:
  "01-python-basics/intro.ipynb":
    order: 1
    description: An empty notebook for you to practice with
  
  # --- Installing packages per notebook/section ---
  # You can control which packages are installed at the top of notebooks by
  # adding either 'install' (string or list) or 'packages' (alias of install)
  # under the metadata key. Globs are supported, e.g. "03-apis/*.ipynb".
  #
  # Example shapes:
  #   "path/to/notebook.ipynb":
  #     install: pandas
  #   "path/to/notebook.ipynb":
  #     install: [pandas, requests]
  #   "03-apis/*.ipynb":
  #     packages: [requests, pandas]
  #
  # The cell is injected at the top of both published docs notebooks and the
  # Codespaces worksheets. If nothing is specified, no installs are added.
  # Pattern-based installs for targeted notebooks/sections
  # Use either 'packages' (alias) or 'install'. These drive %pip install cells
  # injected at the top of notebooks when publishing and in Codespaces worksheets.
  "02-pandas/*.ipynb":
    packages:
      - pandas
  "03-apis/*.ipynb":
    packages:
      - pandas
      - requests
      - matplotlib
      - altair
  "04-scraping/*.ipynb":
    packages:
      - pandas
      - requests
      - playwright
      - matplotlib
      - altair
      - beautifulsoup
  "05-ai/*.ipynb":
    packages:
      - openai
      - instructor
      - tqdm
      - pydantic
      - matplotlib
      - altair
  "06-visualization/*.ipynb":
    packages:
      - matplotlib
      - seaborn
      - pandas
      - matplotlib
      - altair
